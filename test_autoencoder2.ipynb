{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from tpot.config.classifier_nn import classifier_config_nn\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.config import classifier_config_dict_light\n",
    "from tpot.config import classifier_config_dict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_config = classifier_config_dict_light\n",
    "personal_config = classifier_config_dict\n",
    "personal_config['tpot.builtins.SimpleAutoencoder'] = {\n",
    "    'encoding_dim': [10],\n",
    "    'activation': ['relu'],\n",
    "    'optimizer': ['adadelta'],\n",
    "    'loss':['binary_crossentropy'],\n",
    "    'epochs':[100],\n",
    "    'batch_size':[200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding function\n",
    "\n",
    "#function that takes in a features pandas dataframe and turns it into a numpy array \n",
    "#with only the categorical variables one-hot encoded (and leaving out one of the features \n",
    "#of every one-hot encoded variable as baseline)\n",
    "#@param:  features is a pandas df of features; threshold number is the number of unique values \n",
    "#a variable should have in order to be considered categorical\n",
    "#@return:  a numpy matrix containing the original dataset but with the categorical variables\n",
    "#one hot encoded and one of the one hot encoded features per cat variable left out; \n",
    "#for example an original feature set of 10 categorical variables with three categories each will \n",
    "#be transoformed into a numpy array with 20 dichotomous variables\n",
    "\n",
    "def one_hot_encode(features, cat_threshold_number = 5):\n",
    "    num_unique_vals_dict = {}\n",
    "    feature_names = list(features)\n",
    "    for feature in feature_names:\n",
    "        label_encoder = LabelEncoder()\n",
    "        features.loc[:, feature] = label_encoder.fit_transform(features.loc[:, feature])\n",
    "        num_unique_vals_dict[feature] = len(label_encoder.classes_)\n",
    "\n",
    "    features_to_onehot = []\n",
    "    for feature in num_unique_vals_dict:\n",
    "        if num_unique_vals_dict[feature] <= cat_threshold_number and num_unique_vals_dict[feature] > 1:\n",
    "            features_to_onehot = features_to_onehot + [feature]\n",
    "\n",
    "    #create index array listing indices in orginal feature names array that are present in features_to_onehot\n",
    "    indices_to_onehot = np.nonzero(np.in1d(feature_names, features_to_onehot))\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(categorical_features = indices_to_onehot, sparse = False)\n",
    "    features = onehot_encoder.fit_transform(features)\n",
    "\n",
    "    idx_to_delete = np.cumsum([0] + list(num_unique_vals_dict.values()))\n",
    "\n",
    "    idx_to_keep = [i for i in range(features.shape[1]) if i not in idx_to_delete]\n",
    "\n",
    "    features = features[:, idx_to_keep]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "data = pd.read_table(\"sample_data.txt\")\n",
    "data = data.iloc[:, :11]\n",
    "dv = data.iloc[:, 10:11]\n",
    "features = data.iloc[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode data, then split it into training and validation\n",
    "X = one_hot_encode(features)\n",
    "y = dv\n",
    "y = pd.np.array(y).ravel()\n",
    "#split data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_val = x_val.reshape((len(x_val)), np.prod(x_val.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot.builtins import SimpleAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SimpleAutoencoder(encoding_dim=10, \n",
    "                        activation='relu', \n",
    "                        optimizer='adadelta', \n",
    "                        loss='binary_crossentropy', \n",
    "                        epochs=100, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleAutoencoder(activation='relu', batch_size=200, encoding_dim=10,\n",
       "         epochs=100, loss='binary_crossentropy', optimizer='adadelta',\n",
       "         random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.transform(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=10, config_dict=personal_config,\n",
    "                        population_size=10, verbosity=3,\n",
    "                        template = 'SimpleAutoencoder-Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bf4d656f1e4153b81cc38ec14555da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=110), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #10 due to time out. Continuing to the next pipeline.\n"
     ]
    }
   ],
   "source": [
    "tpot.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('simpleautoencoder', SimpleAutoencoder(activation='relu', batch_size=200, encoding_dim=3,\n",
       "         epochs=100, loss='binary_crossentropy', optimizer='adadelta',\n",
       "         random_state=42)), ('randomforestclassifier', RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "            crite...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7373134328358208"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c81f46ca1934cbb804f3c7eeaf0d351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=110), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t0.739123264213602\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t0.739123264213602\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t0.739123264213602\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "Generation 4 - Current Pareto front scores:\n",
      "-1\t0.7851587509403691\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=10, DecisionTreeClassifier__min_samples_leaf=2, DecisionTreeClassifier__min_samples_split=10)\n",
      "\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 5 - Current Pareto front scores:\n",
      "-1\t0.7851587509403691\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=10, DecisionTreeClassifier__min_samples_leaf=2, DecisionTreeClassifier__min_samples_split=10)\n",
      "-2\t0.7940354202255223\tExtraTreesClassifier(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=6), ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "-1\t0.7941029189890149\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=10, DecisionTreeClassifier__min_samples_leaf=3, DecisionTreeClassifier__min_samples_split=10)\n",
      "-2\t0.7988703101036172\tRandomForestClassifier(ZeroCount(input_matrix), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.7000000000000001, RandomForestClassifier__min_samples_leaf=4, RandomForestClassifier__min_samples_split=13, RandomForestClassifier__n_estimators=100)\n",
      "-3\t0.8105762748496448\tExtraTreesClassifier(RFE(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=6), RFE__ExtraTreesClassifier__criterion=entropy, RFE__ExtraTreesClassifier__max_features=0.55, RFE__ExtraTreesClassifier__n_estimators=100, RFE__step=0.6000000000000001), ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 7 - Current Pareto front scores:\n",
      "-1\t0.7941029189890149\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=10, DecisionTreeClassifier__min_samples_leaf=3, DecisionTreeClassifier__min_samples_split=10)\n",
      "-2\t0.8225075125625008\tExtraTreesClassifier(RFE(input_matrix, RFE__ExtraTreesClassifier__criterion=entropy, RFE__ExtraTreesClassifier__max_features=0.55, RFE__ExtraTreesClassifier__n_estimators=100, RFE__step=0.6000000000000001), ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "-3\t0.8538837973873324\tExtraTreesClassifier(RFE(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=6), RFE__ExtraTreesClassifier__criterion=entropy, RFE__ExtraTreesClassifier__max_features=0.55, RFE__ExtraTreesClassifier__n_estimators=100, RFE__step=0.6000000000000001), ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "Generation 8 - Current Pareto front scores:\n",
      "-1\t0.7941029189890149\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=10, DecisionTreeClassifier__min_samples_leaf=3, DecisionTreeClassifier__min_samples_split=10)\n",
      "-2\t0.8747700927276731\tExtraTreesClassifier(RFE(input_matrix, RFE__ExtraTreesClassifier__criterion=entropy, RFE__ExtraTreesClassifier__max_features=0.55, RFE__ExtraTreesClassifier__n_estimators=100, RFE__step=0.6000000000000001), ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "-3\t0.8882238764406871\tExtraTreesClassifier(RFE(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=10), RFE__ExtraTreesClassifier__criterion=entropy, RFE__ExtraTreesClassifier__max_features=0.55, RFE__ExtraTreesClassifier__n_estimators=100, RFE__step=0.6000000000000001), ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=2, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 9 - Current Pareto front scores:\n",
      "-1\t0.7941029189890149\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=10, DecisionTreeClassifier__min_samples_leaf=3, DecisionTreeClassifier__min_samples_split=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\t0.8747700927276731\tExtraTreesClassifier(RFE(input_matrix, RFE__ExtraTreesClassifier__criterion=entropy, RFE__ExtraTreesClassifier__max_features=0.55, RFE__ExtraTreesClassifier__n_estimators=100, RFE__step=0.6000000000000001), ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "-3\t0.8882238764406871\tExtraTreesClassifier(RFE(DecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=10), RFE__ExtraTreesClassifier__criterion=entropy, RFE__ExtraTreesClassifier__max_features=0.55, RFE__ExtraTreesClassifier__n_estimators=100, RFE__step=0.6000000000000001), ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=2, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
      "Generation 10 - Current Pareto front scores:\n",
      "-1\t0.8152661088874759\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.8500000000000001, ExtraTreesClassifier__min_samples_leaf=2, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.9597453833588947\tDecisionTreeClassifier(RFE(input_matrix, RFE__ExtraTreesClassifier__criterion=entropy, RFE__ExtraTreesClassifier__max_features=0.35000000000000003, RFE__ExtraTreesClassifier__n_estimators=100, RFE__step=0.9000000000000001), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=10, DecisionTreeClassifier__min_samples_leaf=3, DecisionTreeClassifier__min_samples_split=10)\n",
      "\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "        disable_update_check=False, early_stop=None, generations=10,\n",
       "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=10,\n",
       "        random_state=None, scoring=None, subsample=1.0,\n",
       "        template='RandomTree', use_dask=False, verbosity=3,\n",
       "        warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare with regular TPOT\n",
    "tpot_reg = TPOTClassifier(generations=10, population_size=10, verbosity=3)\n",
    "tpot_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850746268656716"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_reg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
