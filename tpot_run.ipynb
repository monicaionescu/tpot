{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from tpot.config.classifier_nn import classifier_config_nn\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.config import classifier_config_dict_light\n",
    "from tpot.config import classifier_config_dict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "personal_config = classifier_config_dict_light\n",
    "personal_config = classifier_config_dict\n",
    "personal_config['tpot.builtins.SimpleAutoencoder'] = {\n",
    "    'activation': ['relu'],\n",
    "    'optimizer': ['adadelta'],\n",
    "    'loss':['binary_crossentropy'],\n",
    "    'epochs':['500'],\n",
    "    'batch_size':['200']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding function\n",
    "\n",
    "#function that takes in a features pandas dataframe and turns it into a numpy array \n",
    "#with only the categorical variables one-hot encoded (and leaving out one of the features \n",
    "#of every one-hot encoded variable as baseline)\n",
    "#@param:  features is a pandas df of features; threshold number is the number of unique values \n",
    "#a variable should have in order to be considered categorical\n",
    "#@return:  a numpy matrix containing the original dataset but with the categorical variables\n",
    "#one hot encoded and one of the one hot encoded features per cat variable left out; \n",
    "#for example an original feature set of 10 categorical variables with three categories each will \n",
    "#be transoformed into a numpy array with 20 dichotomous variables\n",
    "\n",
    "def one_hot_encode(features, cat_threshold_number = 5):\n",
    "    num_unique_vals_dict = {}\n",
    "    feature_names = list(features)\n",
    "    for feature in feature_names:\n",
    "        label_encoder = LabelEncoder()\n",
    "        features.loc[:, feature] = label_encoder.fit_transform(features.loc[:, feature])\n",
    "        num_unique_vals_dict[feature] = len(label_encoder.classes_)\n",
    "\n",
    "    features_to_onehot = []\n",
    "    for feature in num_unique_vals_dict:\n",
    "        if num_unique_vals_dict[feature] <= cat_threshold_number and num_unique_vals_dict[feature] > 1:\n",
    "            features_to_onehot = features_to_onehot + [feature]\n",
    "\n",
    "    #create index array listing indices in orginal feature names array that are present in features_to_onehot\n",
    "    indices_to_onehot = np.nonzero(np.in1d(feature_names, features_to_onehot))\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(categorical_features = indices_to_onehot, sparse = False)\n",
    "    features = onehot_encoder.fit_transform(features)\n",
    "\n",
    "    idx_to_delete = np.cumsum([0] + list(num_unique_vals_dict.values()))\n",
    "\n",
    "    idx_to_keep = [i for i in range(features.shape[1]) if i not in idx_to_delete]\n",
    "\n",
    "    features = features[:, idx_to_keep]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in data\n",
    "data = pd.read_table(\"sample_data.txt\")\n",
    "data = data.iloc[:, :11]\n",
    "dv = data.iloc[:, 10:11]\n",
    "features = data.iloc[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot encode data, then split it into training and validation\n",
    "X = one_hot_encode(features)\n",
    "y = dv\n",
    "y = pd.np.array(y).ravel()\n",
    "#split data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_val = x_val.reshape((len(x_val)), np.prod(x_val.shape[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=10, config_dict=personal_config,\n",
    "                        population_size=10, verbosity=2,\n",
    "                        template = 'SimpleAutoencoder-Classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "free variable 'optype' referenced before assignment in enclosing scope",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-36b7a0ded4b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Box\\MonicaThesis\\tpot\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m         \"\"\"\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Box\\MonicaThesis\\tpot\\tpot\\base.py\u001b[0m in \u001b[0;36m_fit_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_pset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_toolbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Box\\MonicaThesis\\tpot\\tpot\\base.py\u001b[0m in \u001b[0;36m_setup_pset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrimitiveSetTyped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MAIN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOutput_Array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenameArguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mARG0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'input_matrix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_operators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbosity\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Box\\MonicaThesis\\tpot\\tpot\\base.py\u001b[0m in \u001b[0;36m_add_operators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    470\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'DatasetSelector'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# dataset selector is not considered as a main type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m                             \u001b[0marg_types\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameter_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m                             \u001b[1;32mif\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m                                 \u001b[0mp_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep_in_type\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0marg_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_ret_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddPrimitive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mp_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Box\\MonicaThesis\\tpot\\tpot\\operator_utils.py\u001b[0m in \u001b[0;36mop_type\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;34m\"Classifier\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Regressor\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Selector\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Transformer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \"\"\"\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moptype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mclass_profile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: free variable 'optype' referenced before assignment in enclosing scope"
     ]
    }
   ],
   "source": [
    "tpot.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
