{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from tpot.config.classifier_nn import classifier_config_nn\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# from tpot.config import classifier_config_dict_light\n",
    "from tpot.config import classifier_config_dict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal_config = classifier_config_dict_light\n",
    "personal_config = classifier_config_dict\n",
    "personal_config['tpot.builtins.SparseAutoencoder'] = {\n",
    "    'regularizer':['l1', 'l2', 'l1_l2'],\n",
    "    'reg_constant':[10e-4, 10e-5, 10e-6],\n",
    "    'encoding_dim': [10, 50, 100, 500],\n",
    "    'activation': ['relu'],\n",
    "    'optimizer': ['adadelta'],\n",
    "    'loss':['binary_crossentropy'],\n",
    "    'epochs':[10],\n",
    "    'batch_size':[10, 15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new data\n",
    "new_data = pd.read_csv(\"processed_aml_data.csv\")\n",
    "X = new_data.iloc[:, 1:5051]\n",
    "y = new_data.iloc[:, 5051]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert X and y to numpy\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, train_size = 0.8, test_size = 0.20, random_state = 42)\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "# x_val = x_val.reshape((len(x_val)), np.prod(x_val.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 5050)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot.builtins import SparseAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SparseAutoencoder(encoding_dim=40,\n",
    "                        regularizer = 'l1',\n",
    "                        reg_constant = '10e-5',\n",
    "                        activation='relu', \n",
    "                        optimizer='adadelta', \n",
    "                        loss='binary_crossentropy', \n",
    "                        epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\monicai\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\monicai\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(activation='relu', batch_size=10, encoding_dim=40,\n",
       "         epochs=10, loss='binary_crossentropy', optimizer='adadelta',\n",
       "         random_state=42, reg_constant='10e-5', regularizer='l1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=10, config_dict=personal_config,\n",
    "                        population_size=10, verbosity=3,\n",
    "                        template = 'SparseAutoencoder-RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa42c0077fa47dabbc84731bbe1f19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=110, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Generation 6 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Generation 7 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Skipped pipeline #86 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #88 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #90 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #92 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #94 due to time out. Continuing to the next pipeline.\n",
      "Generation 8 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Skipped pipeline #96 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #98 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #100 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #102 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #104 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #106 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #108 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #110 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #112 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #114 due to time out. Continuing to the next pipeline.\n",
      "Generation 9 - Current Pareto front scores:\n",
      "-2\t0.6551587301587302\tRandomForestClassifier(SparseAutoencoder(input_matrix, SparseAutoencoder__activation=relu, SparseAutoencoder__batch_size=15, SparseAutoencoder__encoding_dim=100, SparseAutoencoder__epochs=10, SparseAutoencoder__loss=binary_crossentropy, SparseAutoencoder__optimizer=adadelta, SparseAutoencoder__reg_constant=1e-05, SparseAutoencoder__regularizer=l1), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=1.0, RandomForestClassifier__min_samples_leaf=11, RandomForestClassifier__min_samples_split=20, RandomForestClassifier__n_estimators=100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "tpot.fit(x_train, y_train)\n",
    "#end = time.time()\n",
    "#print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.score(x_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
