{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from tpot.config.classifier_nn import classifier_config_nn\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.config import classifier_config_dict_light\n",
    "from tpot.config import classifier_config_dict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_config = classifier_config_dict_light\n",
    "personal_config = classifier_config_dict\n",
    "personal_config['tpot.builtins.SimpleAutoencoder'] = {\n",
    "    'regularizer' :['regularizers.l1(10e-5)', 'regularizers.l2(10e-5)', 'regularizers.l1_l2(10e-5, 10e-5)'],\n",
    "    'encoding_dim': [40],\n",
    "    'activation': ['relu'],\n",
    "    'optimizer': ['adadelta', \"SGD\"],\n",
    "    'loss':['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_logarithmic_error',\n",
    "       'squared_hinge', 'hinge', 'logcosh', 'binary_crossentropy', 'kullback_leibler_divergence', 'cosine_proximity', 'poisson'],\n",
    "    'epochs':[100],\n",
    "    'batch_size':[200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding function\n",
    "\n",
    "#function that takes in a features pandas dataframe and turns it into a numpy array \n",
    "#with only the categorical variables one-hot encoded (and leaving out one of the features \n",
    "#of every one-hot encoded variable as baseline)\n",
    "#@param:  features is a pandas df of features; threshold number is the number of unique values \n",
    "#a variable should have in order to be considered categorical\n",
    "#@return:  a numpy matrix containing the original dataset but with the categorical variables\n",
    "#one hot encoded and one of the one hot encoded features per cat variable left out; \n",
    "#for example an original feature set of 10 categorical variables with three categories each will \n",
    "#be transoformed into a numpy array with 20 dichotomous variables\n",
    "\n",
    "def one_hot_encode(features, cat_threshold_number = 5):\n",
    "    num_unique_vals_dict = {}\n",
    "    feature_names = list(features)\n",
    "    for feature in feature_names:\n",
    "        label_encoder = LabelEncoder()\n",
    "        features.loc[:, feature] = label_encoder.fit_transform(features.loc[:, feature])\n",
    "        num_unique_vals_dict[feature] = len(label_encoder.classes_)\n",
    "\n",
    "    features_to_onehot = []\n",
    "    for feature in num_unique_vals_dict:\n",
    "        if num_unique_vals_dict[feature] <= cat_threshold_number and num_unique_vals_dict[feature] > 1:\n",
    "            features_to_onehot = features_to_onehot + [feature]\n",
    "\n",
    "    #create index array listing indices in orginal feature names array that are present in features_to_onehot\n",
    "    indices_to_onehot = np.nonzero(np.in1d(feature_names, features_to_onehot))\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(categorical_features = indices_to_onehot, sparse = False)\n",
    "    features = onehot_encoder.fit_transform(features)\n",
    "\n",
    "    idx_to_delete = np.cumsum([0] + list(num_unique_vals_dict.values()))\n",
    "\n",
    "    idx_to_keep = [i for i in range(features.shape[1]) if i not in idx_to_delete]\n",
    "\n",
    "    features = features[:, idx_to_keep]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "data = pd.read_table(\"sample_data.txt\")\n",
    "data = data.iloc[:, :11]\n",
    "dv = data.iloc[:, 10:11]\n",
    "features = data.iloc[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode data, then split it into training and validation\n",
    "X = one_hot_encode(features)\n",
    "y = dv\n",
    "y = pd.np.array(y).ravel()\n",
    "#split data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_val = x_val.reshape((len(x_val)), np.prod(x_val.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SparseAutoencoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4d6fcf83870a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltins\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparseAutoencoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SparseAutoencoder'"
     ]
    }
   ],
   "source": [
    "from tpot.builtins import SparseAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparseAutoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e32a308f76df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m sae = SparseAutoencoder(encoding_dim=10, \n\u001b[0m\u001b[0;32m      2\u001b[0m                         \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adadelta'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         epochs=100, batch_size=200)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SparseAutoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "sae = SparseAutoencoder(encoding_dim=10, \n",
    "                        activation='relu', \n",
    "                        optimizer='adadelta', \n",
    "                        loss='binary_crossentropy', \n",
    "                        epochs=100, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-91810bd4a590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sae' is not defined"
     ]
    }
   ],
   "source": [
    "sae.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e2abae33d884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sae' is not defined"
     ]
    }
   ],
   "source": [
    "sae.transform(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'template'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-251435363198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m tpot = TPOTClassifier(generations=10, config_dict=personal_config,\n\u001b[0;32m      2\u001b[0m                         \u001b[0mpopulation_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                         template = 'SparseAutoencoder-Classifier')\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'template'"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=10, config_dict=personal_config,\n",
    "                        population_size=10, verbosity=3,\n",
    "                        template = 'SparseAutoencoder-Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
