{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from tpot.config.classifier_nn import classifier_config_nn\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# from tpot.config import classifier_config_dict_light\n",
    "from tpot.config import classifier_config_dict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal_config = classifier_config_dict_light\n",
    "personal_config = classifier_config_dict\n",
    "personal_config['tpot.builtins.SimpleAutoencoder'] = {\n",
    "    'encoding_dim': [10, 50, 100, 500],\n",
    "    'activation': ['relu'],\n",
    "    'optimizer': ['adadelta', \"SGD\", \"Adam\", \"Adamax\", \"Nadam\"],\n",
    "    'loss':['binary_crossentropy', 'hinge', 'mean_squared_error', 'mean_absolute_error'],\n",
    "    'epochs':[50, 100],\n",
    "    'batch_size':[10, 15]\n",
    "}\n",
    "\n",
    "# personal_config['tpot.builtins.SimpleAutoencoder'] = {\n",
    "#     'regularizer' :['regularizers.l1(10e-5)', 'regularizers.l2(10e-5)', 'regularizers.l1_l2(10e-5, 10e-5)'],\n",
    "#     'encoding_dim': [40],\n",
    "#     'activation': ['relu'],\n",
    "#     'optimizer': ['adadelta', \"SGD\"],\n",
    "#     'loss':['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_logarithmic_error',\n",
    "#        'squared_hinge', 'hinge', 'logcosh', 'binary_crossentropy', 'kullback_leibler_divergence', 'cosine_proximity', 'poisson'],\n",
    "#     'epochs':[100],\n",
    "#     'batch_size':[200]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new data\n",
    "new_data = pd.read_csv(\"processed_aml_data.csv\")\n",
    "X = new_data.iloc[:, 1:5051]\n",
    "y = new_data.iloc[:, 5051]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert X and y to numpy\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, train_size = 0.8, test_size = 0.20, random_state = 42)\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "# x_val = x_val.reshape((len(x_val)), np.prod(x_val.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 5050)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot.builtins import SimpleAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SimpleAutoencoder(encoding_dim=10, \n",
    "                        activation='relu', \n",
    "                        optimizer='adadelta', \n",
    "                        loss='binary_crossentropy', \n",
    "                        epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleAutoencoder(activation='relu', batch_size=10, encoding_dim=10,\n",
       "         epochs=50, loss='binary_crossentropy', optimizer='adadelta',\n",
       "         random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=50, config_dict=personal_config,\n",
    "                        population_size=100, verbosity=3,\n",
    "                        template = 'SimpleAutoencoder-RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "0.000997304916381836\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"time\")\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3619b6ebff7347438595a86cc8888b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=5100, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #55 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #88 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #93 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #95 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #99 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #105 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #109 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #111 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #113 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #115 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #117 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #119 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #121 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #123 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #125 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #127 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #129 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #131 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #133 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #135 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #137 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #139 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #141 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #143 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #145 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #147 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #149 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #151 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #153 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #155 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #157 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #159 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #161 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #163 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #165 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #167 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #169 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #171 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #173 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #175 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #177 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #179 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #181 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #183 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #185 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #187 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #189 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #191 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #193 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #195 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #197 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #199 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #201 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #203 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #205 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #207 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #209 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #211 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #213 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #215 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #217 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #219 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #221 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #223 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #225 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #227 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #229 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #231 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #233 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #235 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #237 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #239 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #241 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #243 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #245 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #247 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #249 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #251 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #253 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #255 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #257 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #259 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #261 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #263 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #265 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #267 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #269 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "49845.716542720795\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tpot.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('simpleautoencoder', SimpleAutoencoder(activation='relu', batch_size=15, encoding_dim=50,\n",
       "         epochs=10, loss='binary_crossentropy', optimizer='adadelta',\n",
       "         random_state=42)), ('randomforestclassifier', RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "            criter...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
